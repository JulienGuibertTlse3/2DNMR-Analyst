runApp('Shine.R')
runApp('Shine.R')
runApp('Shine.R')
runApp('Shine.R')
runApp('Shine.R')
runApp('Shine.R')
runApp('Shine.R')
runApp('Shine.R')
runApp('Shine.R')
runApp('Shine.R')
resss <- read_bruker(dir = "C:/Users/norouchon/Documents/Test_N/UFCOSY/pdata/1", dim = "2D")
rr <- resss$spectrumData
str(rr)
get_spectrum_params <- function(spectrum_type) {
switch(spectrum_type,
"TOCSY" = list(
int_thres = 0.01,
int_prop = 0.001,
eps_value = 0.0068,
pred_class_thres = 0.00001
),
"TOCSY_COMPLEX" = list(  #fonctionne pour les spectres complexes type 201, 203 ou issu de MTH interlabo
int_thres = 0.1,
int_prop = 0.001,
eps_value = 0.0068,
pred_class_thres = 0.01
),
"HSQC" = list(
int_thres = 0.001,
int_prop = 0.5,
eps_value = 0.014,
pred_class_thres = 0.001
),
"COSY" = list(
int_thres = 0.001,
int_prop = 0.5,
eps_value = 0.0068,
pred_class_thres = 0.001
),
"UFCOSY" = list(
int_thres = 0.001,
int_prop = 0.5,
eps_value = 0.02,
pred_class_thres = 0.001
),
stop("Type de spectre inconnu")
)
}
params <- get_spectrum_params("UFCOSY")
# === Normalisation globale du spectre 2D ===
rr_abs <- abs(rr)
rr_norm <- (rr_abs - min(rr_abs)) / (max(rr_abs) - min(rr_abs))
rr_log <- log1p(rr_norm * 100)  # log(1+x), on peut ajuster le facteur
rr_log <- rr_log / max(rr_log)  # renormaliser entre 0 et 1
rownames(rr) <- as.numeric(rownames(rr))  # F2 (lignes)
colnames(rr) <- as.numeric(colnames(rr))  # F1 (colonnes)
#===Affichage===
n_row <- nrow(rr_norm)
n_col <- ncol(rr_norm)
ppm_x <- seq(14, 0, length.out = n_col)  # axe x
ppm_y <- seq(14, 0, length.out = n_row)  # axe y
detected_peaks <- data.frame(F2 = numeric(0), F1 = numeric(0))
# Fonction de padding, padding à droite avec des 0
pad_sequence <- function(x, target_length) {
current_length <- length(x)
if (current_length < target_length) {
pad_width <- target_length - current_length
x_padded <- c(x, rep(0, pad_width))
} else {
x_padded <- x
}
return(x_padded)
}
get_detected_peaks_with_intensity <- function(rr_norm, model, target_length = 2048) {
n_row <- nrow(rr_norm)
n_col <- ncol(rr_norm)
detected_peaks <- data.frame(F2 = numeric(0), F1 = numeric(0), Intensity = numeric(0))
# Détection sur les lignes (F2)
pb_row <- txtProgressBar(min = 0, max = n_row, style = 3)
for (i in 1:n_row) {
spec1D_row <- rr_norm[i, ]
# Padding à la taille target_length
spec1D_row_padded <- pad_sequence(spec1D_row, target_length)
input_tensor <- array(spec1D_row_padded, dim = c(1, target_length, 1))
pred_row <- model %>% predict(input_tensor)
# On récupère uniquement les indices correspondant à la vraie longueur (sans padding)
class_labels <- apply(pred_row[[1]][1, 1:length(spec1D_row), ], 1, which.max) - 1
reg_pred <- pred_row[[2]][1, 1:length(spec1D_row), ]  # [vraie longueur, 3]
idx <- which(class_labels %in% c(1, 2))
if (length(idx) > 0) {
peaks <- data.frame(
F2 = as.numeric(rownames(rr_norm))[i],
F1 = as.numeric(colnames(rr_norm))[idx],
Intensity = reg_pred[idx, 2]  # intensité prédite
)
detected_peaks <- rbind(detected_peaks, peaks)
}
setTxtProgressBar(pb_row, i)
}
close(pb_row)
# Détection sur les colonnes (F1)
pb_col <- txtProgressBar(min = 0, max = n_col, style = 3)
for (j in 1:n_col) {
spec1D_col <- rr_norm[, j]
# Padding à la taille target_length
spec1D_col_padded <- pad_sequence(spec1D_col, target_length)
input_tensor <- array(spec1D_col_padded, dim = c(1, target_length, 1))
pred_col <- model %>% predict(input_tensor)
class_labels <- apply(pred_col[[1]][1, 1:length(spec1D_col), ], 1, which.max) - 1
reg_pred <- pred_col[[2]][1, 1:length(spec1D_col), ]
idx <- which(class_labels %in% c(1, 2))
if (length(idx) > 0) {
peaks <- data.frame(
F2 = as.numeric(rownames(rr_norm))[idx],
F1 = as.numeric(colnames(rr_norm))[j],
Intensity = reg_pred[idx, 2]
)
detected_peaks <- rbind(detected_peaks, peaks)
}
setTxtProgressBar(pb_col, j)
}
close(pb_col)
detected_peaks <- unique(detected_peaks)
return(detected_peaks)
}
detected_peaks <- get_detected_peaks_with_intensity(rr_norm, new_model, target_length = 2048)
predict_peaks_1D_batch <- function(spectrum_mat, model, axis = c("rows", "columns"),
threshold_class = NULL, batch_size = NULL, verbose = TRUE) {
axis <- match.arg(axis)
if (verbose) {
cat("Dimension spectre input :", dim(spectrum_mat), "\n")
}
# Si axis = "columns", on transpose pour avoir vecteurs 1D en lignes
mat <- if(axis == "columns") t(spectrum_mat) else spectrum_mat
n_vectors <- nrow(mat)  # nombre de vecteurs (lignes ou colonnes)
n_points <- ncol(mat)
if (verbose) {
cat("Nombre de vecteurs :", n_vectors, " - Points par vecteur :", n_points, "\n")
}
# On suppose que le modèle attend un input shape = (n_vectors, 2048, 1)
# Si la taille diffère, essayer d'ajuster ou avertir
if (n_points != 2048) {
warning(sprintf("Attention: nombre de points par vecteur = %d ≠ 2048, on va donxc s'apprêter à formater", n_points))
}
# Formatage input pour le modèle : [n_vectors, n_points, 1]
input_array <- array(mat, dim = c(n_vectors, n_points, 1))
detected_list <- vector("list", length = ceiling(n_vectors / batch_size))
pb <- txtProgressBar(min = 0, max = n_vectors, style = 3)
idx_list <- 1
for (start_idx in seq(1, n_vectors, by = batch_size)) {
end_idx <- min(start_idx + batch_size - 1, n_vectors)
batch <- input_array[start_idx:end_idx,,,drop=FALSE]
preds <- predict(model, batch, batch_size = batch_size)
probs <- preds[[1]]  # shape: [batch_size, n_points, nb_classes]
regs <- preds[[2]]   # shape: [batch_size, n_points, nb_classes]
# Affichage debug
if (verbose) {
max_prob <- max(probs[,,2])
mean_prob <- mean(probs[,,2])
cat(sprintf("\nBatch %d-%d : max prob pic = %.3f, mean prob pic = %.3f\n",
start_idx, end_idx, max_prob, mean_prob))
}
prob_peak <- probs[,,2]  # probabilité classe pic (index 2)
reg_intensity <- regs[,,2]  # intensité associée
detected_batch <- list()
for (i in seq_len(nrow(prob_peak))) {
idxs <- which(prob_peak[i, ] > threshold_class)
if (length(idxs) > 0) {
df <- data.frame(
F1 = if (axis == "rows") idxs else (start_idx + i - 1),
F2 = if (axis == "rows") (start_idx + i - 1) else idxs,
Intensity = reg_intensity[i, idxs]
)
detected_batch[[length(detected_batch) + 1]] <- df
}
}
if (length(detected_batch) > 0) {
detected_list[[idx_list]] <- do.call(rbind, detected_batch)
} else {
detected_list[[idx_list]] <- NULL
}
setTxtProgressBar(pb, end_idx)
idx_list <- idx_list + 1
}
close(pb)
detected <- do.call(rbind, detected_list)
if (is.null(detected)) detected <- data.frame(F1=numeric(), F2=numeric(), Intensity=numeric())
if (verbose) {
cat("Nombre total de pics détectés :", nrow(detected), "\n")
}
return(detected)
}
#prédiction classique et nettoyage :
start <- Sys.time()
peaks_rows <- predict_peaks_1D_batch(rr_norm, new_model, axis = "rows", threshold_class = params$pred_class_thres, batch_size = 64)
peaks_cols <- predict_peaks_1D_batch(rr_norm, new_model, axis = "columns", threshold_class = params$pred_class_thres, batch_size = 64)
end <- Sys.time()
elapsed <- end - start
print(elapsed)
peaks_all <- rbind(peaks_rows, peaks_cols)
peaks_clean <- peaks_all
filter_peaks_by_proportion <- function(peaks_clean, threshold = NULL, intensity_threshold = NULL) {
# Optionnel : filtrage initial par intensité
if (!is.null(intensity_threshold)) {
peaks_clean <- peaks_clean[peaks_clean$Intensity > intensity_threshold, ]
}
# Calcul total points par colonne (F1)
total_points_per_col <- tapply(peaks_clean$F2, peaks_clean$F1, max)
# Nombre de pics détectés par colonne
peaks_per_col <- table(peaks_clean$F1)
# Proportion de pics par colonne
prop_col <- peaks_per_col / total_points_per_col[names(peaks_per_col)]
# Colonnes à supprimer
cols_to_remove <- names(prop_col[prop_col > threshold])
# Calcul total points par ligne (F2)
total_points_per_row <- tapply(peaks_clean$F1, peaks_clean$F2, max)
# Nombre de pics détectés par ligne
peaks_per_row <- table(peaks_clean$F2)
# Proportion de pics par ligne
prop_row <- peaks_per_row / total_points_per_row[names(peaks_per_row)]
# Lignes à supprimer
rows_to_remove <- names(prop_row[prop_row > threshold])
# Suppression des pics dans lignes/colonnes indésirables
filtered_peaks <- peaks_clean[!(peaks_clean$F1 %in% cols_to_remove) &
!(peaks_clean$F2 %in% rows_to_remove), ]
return(list(
filtered_peaks = filtered_peaks,
removed_columns = cols_to_remove,
removed_rows = rows_to_remove
))
}
filter_noisy_columns <- function(peaks_df, threshold_ratio = 0.9, min_col_max = NULL) {
# max en valeur absolue par colonne F1
max_per_col <- aggregate(Intensity ~ F1, data = peaks_df,
FUN = function(x) max(abs(x)))
colnames(max_per_col)[2] <- "MaxIntensity"
# associer à chaque point le max de sa colonne
merged <- merge(peaks_df, max_per_col, by = "F1")
# filtrer selon amplitude relative
filtered <- subset(merged, abs(Intensity) >= threshold_ratio * MaxIntensity)
# optionnel : enlever carrément les colonnes trop faibles
if (!is.null(min_col_max)) {
filtered <- subset(filtered, MaxIntensity >= min_col_max)
}
# retour format original
filtered <- filtered[, c("F1", "F2", "Intensity")]
return(filtered)
}
clean_peak_clusters_dbscan <- function(peaks_df, ppm_x, ppm_y, eps_ppm = params$eps_value, minPts = 3) {
# Enlever les NA
peaks_df <- peaks_df[!is.na(peaks_df$F1) & !is.na(peaks_df$F2), ]
# Coordonnées normalisées
coords <- as.matrix(peaks_df[, c("F1", "F2")])
# Clustering
clustering <- dbscan::dbscan(coords, eps = eps_ppm, minPts = minPts)
peaks_df$cluster <- clustering$cluster
return(peaks_df)
}
remove_peaks_ppm_range <- function(peaks, rr_norm, axis = "F1", ppm_min, ppm_max) {
# --- get ppm axes from rr_norm ---
ppm_y <- as.numeric(rownames(rr_norm))   # F2 axis (rows)
ppm_x <- as.numeric(colnames(rr_norm))   # F1 axis (cols)
# --- helper pour convertir indices ou ppm → ppm réel ---
map_to_ppm <- function(vals, ppm_axis) {
vnum <- as.numeric(vals)
n <- length(ppm_axis)
axis_min <- min(ppm_axis, na.rm = TRUE)
axis_max <- max(ppm_axis, na.rm = TRUE)
if (all(!is.na(vnum) & vnum >= 1 & vnum <= n & abs(vnum - round(vnum)) < 1e-6)) {
return(as.numeric(ppm_axis[round(vnum)]))
}
if (all(!is.na(vnum) & vnum >= axis_min & vnum <= axis_max)) {
return(as.numeric(sapply(vnum, function(v) ppm_axis[which.min(abs(ppm_axis - v))])))
}
sapply(vnum, function(v) {
if (is.na(v)) return(NA_real_)
if (v >= 1 && v <= n && abs(v - round(v)) < 1e-6) {
return(ppm_axis[round(v)])
} else if (v >= axis_min && v <= axis_max) {
return(ppm_axis[which.min(abs(ppm_axis - v))])
} else {
return(ppm_axis[which.min(abs(ppm_axis - v))])
}
})
}
# --- conversion ---
ppm_vals <- if (axis == "F1") {
map_to_ppm(peaks$F1, ppm_x)
} else if (axis == "F2") {
map_to_ppm(peaks$F2, ppm_y)
} else {
stop("axis doit être 'F1' ou 'F2'")
}
# --- filtre ---
mask <- ppm_vals >= ppm_min & ppm_vals <= ppm_max
removed <- sum(mask, na.rm = TRUE)
message("Retiré ", removed, " pics entre ", ppm_min, " et ", ppm_max, " ppm (", axis, ")")
return(peaks[!mask, , drop = FALSE])
}
result <- filter_peaks_by_proportion(peaks_clean, threshold = 0.5, intensity_threshold = params$int_thres) # intensity_threshold à 0.001 de base
peaks_clean_filtered <- result$filtered_peaks
peaks_clean_filtered <- filter_noisy_columns(peaks_clean_filtered)
plot_peaks_ppm_plotly_clean <- function(peaks,
rr_norm = NULL,
intensity_threshold = NULL,
ratio = NULL) {
# --- sanity checks ---
peaks <- as.data.frame(peaks, stringsAsFactors = FALSE)
if (!all(c("F1", "F2", "Intensity") %in% colnames(peaks))) {
stop("peaks must be a data.frame with columns: F1, F2, Intensity")
}
if (!is.null(intensity_threshold)) {
peaks <- peaks[peaks$Intensity > intensity_threshold, , drop = FALSE]
}
if (nrow(peaks) == 0) {
warning("No peaks after thresholding -> returning empty plot.")
return(plot_ly() %>% layout(title = "No peaks"))
}
if (is.null(rr_norm)) stop("You must provide rr_norm (matrix/data.frame with rownames and colnames as ppm).")
# --- get ppm axes from rr_norm ---
ppm_y <- as.numeric(rownames(rr_norm))   # F2 axis (rows)
ppm_x <- as.numeric(colnames(rr_norm))   # F1 axis (cols)
if (any(is.na(ppm_x)) || any(is.na(ppm_y))) stop("rownames(rr_norm) and colnames(rr_norm) must be numeric/convertible to numeric ppm values.")
# --- mapping helper (handles indices or ppm values) ---
map_to_ppm <- function(vals, ppm_axis) {
vnum <- as.numeric(vals)
n <- length(ppm_axis)
axis_min <- min(ppm_axis, na.rm = TRUE)
axis_max <- max(ppm_axis, na.rm = TRUE)
# CASE 1: all values look like integer indices in [1..n]
if (all(!is.na(vnum) & vnum >= 1 & vnum <= n & abs(vnum - round(vnum)) < 1e-6)) {
idx <- pmax(1, pmin(n, round(vnum)))
return(as.numeric(ppm_axis[idx]))
}
# CASE 2: all values fall inside the ppm axis range -> map to nearest ppm point
if (all(!is.na(vnum) & vnum >= axis_min & vnum <= axis_max)) {
return(as.numeric(sapply(vnum, function(v) ppm_axis[which.min(abs(ppm_axis - v))])))
}
# FALLBACK: handle element-wise
sapply(vnum, function(v) {
if (is.na(v)) return(NA_real_)
if (v >= 1 && v <= n && abs(v - round(v)) < 1e-6) {
return(ppm_axis[round(v)])
} else if (v >= axis_min && v <= axis_max) {
return(ppm_axis[which.min(abs(ppm_axis - v))])
} else {
# map to closest ppm anyway
return(ppm_axis[which.min(abs(ppm_axis - v))])
}
})
}
# --- compute ppm coords ---
F1_ppm <- map_to_ppm(peaks$F1, ppm_x)
F2_ppm <- map_to_ppm(peaks$F2, ppm_y)
# attach hover text
hover_text <- paste0(
"F1: ", round(F1_ppm, 5), " ppm",
"<br>F2: ", round(F2_ppm, 5), " ppm",
"<br>Intensity: ", signif(peaks$Intensity, 5)
)
# --- build plotly scatter ---
xaxis <- list(title = "F1 (ppm)", autorange = "reversed")
if (!is.null(ratio)) {
yaxis <- list(title = "F2 (ppm)", autorange = "reversed", scaleanchor = "x", scaleratio = ratio)
} else {
yaxis <- list(title = "F2 (ppm)", autorange = "reversed")
}
p <- plot_ly(
x = ~F1_ppm,
y = ~F2_ppm,
type = "scatter",
mode = "markers",
marker = list(size = 2, color = peaks$Intensity, colorscale = "Viridis", showscale = TRUE),
text = hover_text,
hoverinfo = "text"
) %>%
layout(title = "Detected peaks (ppm scale from rr_norm)",
xaxis = xaxis, yaxis = yaxis, plot_bgcolor = "white")
return(p)
}
p_filtered <- plot_peaks_ppm_plotly_clean(peaks_clean_filtered, rr_norm = rr_norm,
intensity_threshold = params$int_thres, ratio = 1)
p_filtered
# ===================== EXTRACTION ALEATOIRE DE 4 SPECTRES 1D - PLOTS SEPARES ==================================
rr_abs <- abs(rr)
rr_norm <- (rr_abs - min(rr_abs)) / (max(rr_abs) - min(rr_abs))
# === Fonctions utilitaires ===
downsample_matrix <- function(mat, step = 4) {
mat[seq(1, nrow(mat), by = step),
seq(1, ncol(mat), by = step)]
}
downsample_axis <- function(axis_vals, step = 4) {
axis_vals[seq(1, length(axis_vals), by = step)]
}
# === Matrice du spectre ===
z_matrix <- rr_norm  # matrice F2 x F1
x_vals   <- as.numeric(colnames(rr_norm))  # F1 (ppm)
y_vals   <- as.numeric(rownames(rr_norm))  # F2 (ppm)
# === Seuil pour contours ===
contour_start <- 0.01 * max(z_matrix)
# === Downsampling pour alléger le rendu ===
step <- 4
z_small <- downsample_matrix(z_matrix, step = step)
x_small <- downsample_axis(x_vals, step = step)
y_small <- downsample_axis(y_vals, step = step)
# --- 1) Normalisation z-score pour clustering ---
peaks_norm <- peaks_clean_filtered %>%
mutate(
F1_scaled = (F1 - mean(F1, na.rm = TRUE)) / sd(F1, na.rm = TRUE),
F2_scaled = (F2 - mean(F2, na.rm = TRUE)) / sd(F2, na.rm = TRUE)
)
# --- 2) DBSCAN (sur coordonnées normalisées) ---
db <- dbscan::dbscan(peaks_norm[, c("F1_scaled", "F2_scaled")],
eps = params$eps_value, minPts = 2)
# Ajouter cluster_db à peaks_clean_filtered (fusion option 2)
peaks_clean_filtered <- peaks_clean_filtered %>%
mutate(cluster_db = db$cluster)
# --- 3) Bounding boxes + intensité max ---
bounding_boxes <- peaks_clean_filtered %>%
dplyr::filter(cluster_db > 0) %>%   # <--- bien préciser dplyr::filter
group_by(cluster_db) %>%
summarise(
xmin = min(F1, na.rm = TRUE),
xmax = max(F1, na.rm = TRUE),
ymin = min(F2, na.rm = TRUE),
ymax = max(F2, na.rm = TRUE),
cx   = (min(F1, na.rm = TRUE) + max(F1, na.rm = TRUE)) / 2,
cy   = (min(F2, na.rm = TRUE) + max(F2, na.rm = TRUE)) / 2,
intensity = max(Intensity, na.rm = TRUE),
.groups = "drop"
)
# --- 4) Conversion indices → ppm ---
peaks_clean_filtered <- peaks_clean_filtered %>%
mutate(
F1_ppm = x_vals[F1],
F2_ppm = y_vals[F2]
)
bounding_boxes <- bounding_boxes %>%
mutate(
xmin_ppm = x_vals[xmin],
xmax_ppm = x_vals[xmax],
ymin_ppm = y_vals[ymin],
ymax_ppm = y_vals[ymax],
cx_ppm   = x_vals[cx],
cy_ppm   = y_vals[cy]
)
# --- 5) Nettoyage doublons ---
if (nrow(bounding_boxes) > 1) {
to_remove <- c()
for (i in seq_len(nrow(bounding_boxes))) {
current <- bounding_boxes[i, ]
for (j in seq_len(nrow(bounding_boxes))) {
if (i == j) next
compare <- bounding_boxes[j, ]
inside_box <- current$cx_ppm >= compare$xmin_ppm & current$cx_ppm <= compare$xmax_ppm &
current$cy_ppm >= compare$ymin_ppm & current$cy_ppm <= compare$ymax_ppm
lower_intensity <- current$intensity < compare$intensity
if (inside_box && lower_intensity) {
to_remove <- c(to_remove, current$cluster_db)
break
}
}
}
bounding_boxes <- bounding_boxes %>%
dplyr::filter(!cluster_db %in% to_remove)
}
# --- 6) Rectangles pour plotly ---
shapes_list <- lapply(seq_len(nrow(bounding_boxes)), function(i) {
list(
type = "rect",
x0 = bounding_boxes$xmin_ppm[i], x1 = bounding_boxes$xmax_ppm[i],
y0 = bounding_boxes$ymin_ppm[i], y1 = bounding_boxes$ymax_ppm[i],
line = list(color = "red", dash = "dot", width = 2),
fillcolor = "rgba(0,0,0,0)",
xref = "x", yref = "y",
layer = "above"
)
})
# --- 7) Plot contour + pics + bounding boxes ---
p_plotly <- plot_ly(
x = x_small, y = y_small, z = z_small,
type = "contour",
contours = list(
start = contour_start,
end   = max(z_small),
size  = (max(z_small) - contour_start) / 15
),
colorscale = "Greys",
reversescale = TRUE
) %>%
# Pics
# add_markers(
#   data = peaks_clean_filtered,
#   x = ~F1_ppm, y = ~F2_ppm,
#   color = ~Intensity,
#   colors = viridis::viridis(100),
#   marker = list(size = 3),
#   inherit = FALSE
# ) %>%
# Centres clusters
{ if (nrow(bounding_boxes) > 0)
add_markers(., data = bounding_boxes,
x = ~cx_ppm, y = ~cy_ppm,
marker = list(symbol = "x", color = "blue", size = 6),
showlegend = FALSE, inherit = FALSE) else . } %>%
layout(
shapes = shapes_list,
xaxis = list(title = "F1 (ppm)", autorange = "reversed"),
yaxis = list(title = "F2 (ppm)", autorange = "reversed")
)
p_plotly
runApp('Shine.R')
